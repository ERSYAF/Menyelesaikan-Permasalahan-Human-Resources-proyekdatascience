# -*- coding: utf-8 -*-
"""PROJECT PERTAMA DATA SCIENCE

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NrkXGdeL_7PsBnDqwoHGisMjbSRA1TG6

# **Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Jaya Jaya Maju**
- **Nama:** [Era Syafina]
- **Email:** [erasyafina025@gmail.com]
- **ID Dicoding:** [Ersyafin]

# **Business Understanding**

* Mengidentifikasi faktor utama yang memengaruhi tingginya attrition rate di Jaya Jaya Maju.

# **Persiapan**
### Menyiapkan library yang dibutuhkan
"""

# Import library
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score
import joblib

"""### Menyiapkan data yang akan digunakan"""

# Load data
df = pd.read_csv('/content/employee_data.csv')

# Menampilkan 5 data teratas
df

"""# **Data Understanding**"""

# Melihat informasi data
df.info()

"""**Feature Descriptions:**

- **EmployeeId**: Unique identifier for each employee.
- **Attrition**: Indicates if the employee left the company (0 = No, 1 = Yes).
- **Age**: Age of the employee.
- **BusinessTravel**: Frequency of business travel.
- **DailyRate**: Daily salary.
- **Department**: The department where the employee works.
- **DistanceFromHome**: Distance from employeeâ€™s home to the workplace (in kilometers).
- **Education**: Education level  
  - 1 = Below College  
  - 2 = College  
  - 3 = Bachelor  
  - 4 = Master  
  - 5 = Doctor
- **EducationField**: Field of study or education background.
- **EnvironmentSatisfaction**: Satisfaction with the work environment  
  - 1 = Low  
  - 2 = Medium  
  - 3 = High  
  - 4 = Very High
- **Gender**: Gender of the employee.
- **HourlyRate**: Hourly wage.
- **JobInvolvement**: Level of involvement in the job  
  - 1 = Low  
  - 2 = Medium  
  - 3 = High  
  - 4 = Very High
- **JobLevel**: Job level (1 to 5).
- **JobRole**: Specific job role or position.
- **JobSatisfaction**: Job satisfaction rating  
  - 1 = Low  
  - 2 = Medium  
  - 3 = High  
  - 4 = Very High
- **MaritalStatus**: Marital status of the employee.
- **MonthlyIncome**: Monthly salary.
- **MonthlyRate**: Monthly pay rate.
- **NumCompaniesWorked**: Number of companies previously worked at.
- **Over18**: Indicates if the employee is over 18 years old.
- **OverTime**: Indicates if the employee works overtime (Yes/No).
- **PercentSalaryHike**: Percentage increase in salary over the last year.
- **PerformanceRating**: Performance evaluation score  
  - 1 = Low  
  - 2 = Good  
  - 3 = Excellent  
  - 4 = Outstanding
- **RelationshipSatisfaction**: Satisfaction with workplace relationships  
  - 1 = Low  
  - 2 = Medium  
  - 3 = High  
  - 4 = Very High
- **StandardHours**: Standard number of working hours (usually same for all employees).
- **StockOptionLevel**: Level of stock options allocated to the employee.
- **TotalWorkingYears**: Total number of years the employee has worked professionally.
- **TrainingTimesLastYear**: Number of training programs attended last year.
- **WorkLifeBalance**: Employee's work-life balance rating  
  - 1 = Low  
  - 2 = Good  
  - 3 = Excellent  
  - 4 = Outstanding
- **YearsAtCompany**: Number of years the employee has been with the company.
- **YearsInCurrentRole**: Number of years in the current role.
- **YearsSinceLastPromotion**: Number of years since the last promotion.
- **YearsWithCurrManager**: Number of years working with the current manager.

### Periksa data yang duplikat
"""

duplicate_count = df.duplicated().sum()
print("Jumlah duplikasi: ", duplicate_count)

"""### Menangani missing value"""

columns_with_nan = df.columns[df.isnull().any()].tolist()

# Membuat DataFrame untuk menampilkan kolom yang memiliki nilai null beserta tipe datanya
nan_info = pd.DataFrame({
    'Tipe Data': df[columns_with_nan].dtypes,
    'Jumlah Null': df[columns_with_nan].isnull().sum()
})

print("Kolom yang memiliki nilai Null beserta tipe datanya:")
print(nan_info)

# Menghapus kolom yang memiliki nilai null
df = df.dropna()

print("\nJumlah nilai kosong pada kolom Attrition setelah pembersihan:")
print(df['Attrition'].isna().sum())

# Melihat informasi data
df.info()

"""keseluruhan data sudah dibersihkan dan siap untuk dianalisis

# **EDA**

### Univariate Analysis
"""

# Identifikasi kolom numerical
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Univariate analysis untuk numerical variables
plt.figure(figsize=(18, 20))
for i, col in enumerate(numerical_columns, 1):
    plt.subplot(len(numerical_columns) // 3 + 1, 3, i)
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

# Identifikasi kolom categorical
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()

# Univariate analysis untuk categorical variables
plt.figure(figsize=(18, 20))
for i, col in enumerate(categorical_columns, 1):
    plt.subplot(len(categorical_columns) // 3 + 1, 3, i)
    sns.countplot(data=df, x=col)
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Menghapus kolom `EmployeeCount`, `StandardHours`, dan `Over18` karena hanya memiliki satu nilai
df = df.drop(['EmployeeCount', 'StandardHours', 'Over18'], axis=1)

"""### Multivariate Analysis"""

# Identifikasi semua fitur kategorikal dalam dataset
categorical_features = df.select_dtypes(include=['object']).columns.tolist()

# List beberapa palet warna alternatif dari seaborn
palettes = ["pastel", "dark", "colorblind", "muted", "bright", "deep"]

# Membuat plot untuk setiap fitur kategorikal relatif terhadap 'Attrition'
for i, col in enumerate(categorical_features):
    # Gunakan palet warna secara bergantian dari list palettes
    palette = palettes[i % len(palettes)]

    sns.catplot(x=col, hue="Attrition", kind="count", dodge=False, height=4, aspect=3, data=df, palette=palette)
    plt.title(f"Distribusi 'Attrition' Relatif terhadap - {col}")
    plt.xticks(rotation=90)
    plt.show()

"""### Correlation Matrix"""

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# One-hot encoding untuk fitur kategorikal
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Membuat matriks korelasi untuk seluruh fitur (numerik dan kategorikal yang telah dienkode)
correlation_matrix = df_encoded.corr()

# Plot matriks korelasi
plt.figure(figsize=(40, 25))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix of All Variables (Including Encoded Categorical Features)')
plt.show()

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# One-hot encoding untuk fitur kategorikal
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Membuat matriks korelasi untuk seluruh fitur (numerik dan kategorikal yang telah dienkode)
correlation_matrix = df_encoded.corr()

# Ambil korelasi dengan kolom 'Attrition'
attrition_correlation = correlation_matrix["Attrition"].sort_values(ascending=False)

factors = attrition_correlation
factors = factors.drop('Attrition')

print("Factors  correlated with Attrition:")
print(factors)

# Plot the top 10 correlations
plt.figure(figsize=(10, 8))
sns.barplot(x=factors.values, y=factors.index, hue=factors.index, dodge=False, palette="coolwarm", legend=False)
plt.title("Features Most Correlated with Attrition")
plt.xlabel("Correlation with Attrition")
plt.show()

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

# One-hot encoding untuk fitur kategorikal
df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Membuat matriks korelasi untuk seluruh fitur (numerik dan kategorikal yang telah dienkode)
correlation_matrix = df_encoded.corr()

# Ambil korelasi dengan kolom 'Attrition'
attrition_correlation = correlation_matrix["Attrition"].sort_values(ascending=False)

# Ambil 10 fitur dengan korelasi tertinggi terhadap 'Attrition'
top_10_factors = attrition_correlation.head(11)  # Include 'Attrition' itself as well
top_10_factors = top_10_factors.drop('Attrition')  # Remove 'Attrition' as we are interested in other factors

print("Top 10 factors most correlated with Attrition:")
print(top_10_factors)

# Plot the top 10 correlations
plt.figure(figsize=(10, 8))
sns.barplot(x=top_10_factors.values, y=top_10_factors.index, hue=top_10_factors.index, dodge=False, palette="coolwarm", legend=False)
plt.title("Top 10 Features Most Correlated with Attrition")
plt.xlabel("Correlation with Attrition")
plt.show()

"""# **Data Preparation / Preprocessing**"""

df_cleaned = df.copy()
df_cleaned = df_cleaned.drop(['EmployeeId'], axis=1)

# Identifikasi fitur numerik dan kategorikal
categorical_columns = df_cleaned.select_dtypes(include=['object']).columns.tolist()
numerical_columns = df_cleaned.select_dtypes(include=['int64', 'float64']).columns.tolist()
if 'Attrition' in numerical_columns:
    numerical_columns.remove('Attrition')

# Standardisasi fitur numerik
scaler = StandardScaler()
df_cleaned[numerical_columns] = scaler.fit_transform(df_cleaned[numerical_columns])

# One-hot encoding untuk fitur kategorikal
df_encoded = pd.get_dummies(df_cleaned, columns=categorical_columns, drop_first=True)

#Mengubah nilai True dan False menjadi 1 dan 0
df_encoded = df_encoded.astype(int)

# Memisahkan fitur dan target
X = df_encoded.drop('Attrition', axis=1)
y = df_encoded['Attrition']

# Membagi data menjadi set pelatihan dan pengujian
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""# **Modeling**"""

model = RandomForestClassifier(random_state=42)

# Latih model
model.fit(X_train, y_train)

"""# **Evaluation**"""

# Prediksi pada data uji
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

# Evaluasi hasil
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nAUC-ROC Score:", roc_auc_score(y_test, y_proba))
print("\nAccuracy Score:", accuracy_score(y_test, y_pred))

# Menyimpan model yang dilatih
joblib.dump(model, 'model.pkl')

"""# **Upload dataframe ke supabase**"""

from sqlalchemy import create_engine

URL = "postgresql://postgres.dputavcdqrtstdyfebfr:Rafinaaa14_$@aws-0-ap-southeast-1.pooler.supabase.com:6543/postgres"

engine = create_engine(URL)
df.to_sql('dataset', engine)